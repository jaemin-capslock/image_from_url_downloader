{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import matplotlib.pyplot\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "790"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "\n",
    "##a = (r\"D:\\Betastop_dataset\\x_train\\butterfly_url2.txt\",'r').read().splitlines()\n",
    "##test_data.splitlines([\"\\n\"])\n",
    "##test_data = pd.read_csv(r\"D:\\Betastop_dataset\\x_train\\butterfly_url.csv\",)\n",
    "##\"\"\"b = str(a[(a.rfind(\"http\"))+0:])\n",
    "##if 'Name' in b:\n",
    "   ##b = b[:b.find(\"Name\")]\n",
    "##print(len(test_data))\"\"\"\n",
    "\n",
    "f = open(r\"D:\\Betastop_dataset\\x_train\\firefly1_url.txt\", 'r')\n",
    "g = open(r\"D:\\Betastop_dataset\\x_train\\new_papilio_url.txt\", 'r')\n",
    "new_data_list = []\n",
    "for line in g:\n",
    "    b = line[:line.find(\"\\n\")]\n",
    "    new_data_list.append(b)\n",
    "data_list = []\n",
    "for line in f:\n",
    "    a = line[:line.find(\"\\n\")]\n",
    "    data_list.append(a)\n",
    "len(data_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def load_requests(source_url, sink_path):\n",
    "    \"\"\"\n",
    "    Load a file from an URL (e.g. http).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    source_url : str\n",
    "        Where to load the file from.\n",
    "    sink_path : str\n",
    "        Where the loaded file is stored.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(sink_path, 'wb') as handle:\n",
    "        response = requests.get(source_url, stream=True)\n",
    "\n",
    "        if not response.ok:\n",
    "            print (response)\n",
    "\n",
    "        for block in response.iter_content(1024):\n",
    "            if not block:\n",
    "                break\n",
    "\n",
    "            handle.write(block)\n",
    "            \n",
    "    ##with open(sink_path, 'wb') as handle:\n",
    "        ##response = requests.get(source_url, stream=True)\n",
    "    \n",
    "def load_dataset(data, ind):\n",
    "    ##data_index = str(data.loc[ind])\n",
    "    ###if \"Name\" in data_single_line:\n",
    "        ##data_single_line = str(data_single_line[:data_single_line.find(\"Name\")])\n",
    "    \n",
    "    return data[ind]\n",
    "    \n",
    "   \n",
    "def download_images(data, dir):\n",
    "    row_count = len(data)\n",
    "    for l in range(row_count):\n",
    "        \n",
    "            \n",
    "        download_dir = dir + str(1 + l) + \".jpg\"\n",
    "        load_requests(load_dataset(data, l), download_dir)\n",
    "        if l % 10 == 0:\n",
    "            print(str(l) + \"th download initiated\")\n",
    "            \n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "https://static.inaturalist.org/photos/363827/medium.JPG?1370820509\n",
      "0th download initiated\n",
      "10th download initiated\n",
      "20th download initiated\n",
      "30th download initiated\n",
      "40th download initiated\n",
      "50th download initiated\n",
      "60th download initiated\n",
      "70th download initiated\n",
      "80th download initiated\n",
      "90th download initiated\n",
      "100th download initiated\n",
      "110th download initiated\n",
      "120th download initiated\n",
      "130th download initiated\n",
      "140th download initiated\n",
      "150th download initiated\n",
      "160th download initiated\n",
      "170th download initiated\n",
      "180th download initiated\n",
      "190th download initiated\n",
      "200th download initiated\n",
      "210th download initiated\n",
      "220th download initiated\n",
      "230th download initiated\n",
      "240th download initiated\n",
      "250th download initiated\n",
      "260th download initiated\n",
      "270th download initiated\n",
      "280th download initiated\n",
      "290th download initiated\n",
      "300th download initiated\n",
      "310th download initiated\n",
      "320th download initiated\n",
      "330th download initiated\n",
      "340th download initiated\n",
      "350th download initiated\n",
      "360th download initiated\n",
      "370th download initiated\n",
      "380th download initiated\n",
      "390th download initiated\n",
      "400th download initiated\n",
      "410th download initiated\n",
      "420th download initiated\n",
      "430th download initiated\n",
      "440th download initiated\n",
      "450th download initiated\n",
      "460th download initiated\n",
      "470th download initiated\n",
      "480th download initiated\n",
      "490th download initiated\n",
      "500th download initiated\n",
      "510th download initiated\n",
      "520th download initiated\n",
      "530th download initiated\n",
      "540th download initiated\n",
      "550th download initiated\n",
      "560th download initiated\n",
      "570th download initiated\n",
      "580th download initiated\n",
      "590th download initiated\n",
      "600th download initiated\n",
      "610th download initiated\n",
      "620th download initiated\n",
      "630th download initiated\n",
      "640th download initiated\n",
      "650th download initiated\n",
      "660th download initiated\n",
      "670th download initiated\n",
      "680th download initiated\n",
      "690th download initiated\n",
      "700th download initiated\n",
      "710th download initiated\n",
      "720th download initiated\n",
      "730th download initiated\n",
      "740th download initiated\n",
      "750th download initiated\n",
      "760th download initiated\n",
      "770th download initiated\n",
      "780th download initiated\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "butterfly_directory = r\"D:\\Betastop_dataset\\x_train\\butterfly\\pieris_rapae\"\n",
    "new_butterfly_directory = r\"D:\\Betastop_dataset\\x_train\\P_test\\pap\"\n",
    "firefly_directory = r\"D:\\Betastop_dataset\\x_train\\orthetrum_albistylum\\orthetrum_albistylum\"\n",
    "print(load_dataset(data_list,3))\n",
    "##print(load_dataset(test_data,1))\n",
    "download_images(data_list, firefly_directory)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}